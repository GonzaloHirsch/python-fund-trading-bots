{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "\n",
    "This notebook handles pre-processing all the data to make sure it is consistent and there are no gaps in it.\n",
    "\n",
    "Note: This notebook assumes that you have loaded data within the `data/portfolios.json` and `data/pricing` by running the `init.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lib imports.\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Typing\n",
    "from typing import Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATA_PATH = \"data/pricing\"\n",
    "FUNDS_PATH = \"data/portfolios.json\"\n",
    "\n",
    "# Columns.\n",
    "COLUMN_DATE = \"asOfDate\"\n",
    "COLUMN_PRICE = \"price\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition\n",
    "\n",
    "This section defines all the functions we need for later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Loads the data as per the specification of the pricing CSVs.\n",
    "\n",
    "    Args:\n",
    "        path (str): to the current file to load.\n",
    "\n",
    "    Returns:\n",
    "        Optional[pd.DataFrame]: with the pricing data sorted by date, ascending. None if there is no data.\n",
    "    \"\"\"\n",
    "    # Make sure it is a CSV and not something else.\n",
    "    if \".csv\" not in path:\n",
    "        return None\n",
    "\n",
    "    # Loads the data.\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        header=0,\n",
    "        index_col=COLUMN_DATE,\n",
    "        parse_dates=[COLUMN_DATE],\n",
    "        dtype={\n",
    "            \"price\": np.float64,\n",
    "            \"currencyCode\": np.string_,\n",
    "            \"__typename\": np.string_,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Sort by the index that we defined as date.\n",
    "    return df.sort_index(ascending=True, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_gaps(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Fills the gaps in the pricing data by backfilling from the previous existing dates.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): with potential gaps in the date index.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: with no gaps in the index.\n",
    "    \"\"\"\n",
    "    # Get all the possible dates.\n",
    "    date_min, date_max = (df.index.min(), df.index.max())\n",
    "\n",
    "    # We reindex using the min and max dates. This will propagate the values.\n",
    "    return df.reindex(pd.date_range(start=date_min, end=date_max), method=\"ffill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "This section tests the functions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_index_size(df: pd.DataFrame) -> Tuple[int, int]:\n",
    "    # We can expect the number of rows to be less than a range of dates.\n",
    "    full_range_len = len(pd.date_range(start=df.index.min(), end=df.index.max()))\n",
    "    index_len = df.index.shape[0]\n",
    "\n",
    "    print(f\"Full Size vs Index Size = {full_range_len} vs {index_len}\")\n",
    "    return full_range_len, index_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               price currencyCode __typename\n",
      "asOfDate                                    \n",
      "2016-11-08  100.0000          GBP  FundPrice\n",
      "2016-11-09   99.7742          GBP  FundPrice\n",
      "2016-11-10   99.7799          GBP  FundPrice\n",
      "2016-11-11   98.5293          GBP  FundPrice\n",
      "2016-11-14   99.3307          GBP  FundPrice\n",
      "...              ...          ...        ...\n",
      "2024-10-07  218.3068          GBP  FundPrice\n",
      "2024-10-08  218.1539          GBP  FundPrice\n",
      "2024-10-09  219.3834          GBP  FundPrice\n",
      "2024-10-10  219.6460          GBP  FundPrice\n",
      "2024-10-11  220.5142          GBP  FundPrice\n",
      "\n",
      "[2002 rows x 3 columns]\n",
      "Full Size vs Index Size = 2895 vs 2002\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_DATA = \"data/pricing/8617.csv\"\n",
    "\n",
    "df = load_data(EXAMPLE_DATA)\n",
    "\n",
    "# We can verify that there a gap since the gaps occur in weekends where the market is closed.\n",
    "print(df)\n",
    "\n",
    "# Make sure we assert it.\n",
    "full_size, index_size = evaluate_index_size(df)\n",
    "assert full_size > index_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               price currencyCode __typename\n",
      "2016-11-08  100.0000          GBP  FundPrice\n",
      "2016-11-09   99.7742          GBP  FundPrice\n",
      "2016-11-10   99.7799          GBP  FundPrice\n",
      "2016-11-11   98.5293          GBP  FundPrice\n",
      "2016-11-12   98.5293          GBP  FundPrice\n",
      "...              ...          ...        ...\n",
      "2024-10-07  218.3068          GBP  FundPrice\n",
      "2024-10-08  218.1539          GBP  FundPrice\n",
      "2024-10-09  219.3834          GBP  FundPrice\n",
      "2024-10-10  219.6460          GBP  FundPrice\n",
      "2024-10-11  220.5142          GBP  FundPrice\n",
      "\n",
      "[2895 rows x 3 columns]\n",
      "Full Size vs Index Size = 2895 vs 2895\n"
     ]
    }
   ],
   "source": [
    "df = fill_gaps(df)\n",
    "\n",
    "# We can verify that now there shouldn't be any gaps.\n",
    "print(df)\n",
    "\n",
    "# Make sure we assert it.\n",
    "full_size, index_size = evaluate_index_size(df)\n",
    "assert full_size == index_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propagation\n",
    "\n",
    "Now we perform the propagation against ALL the data in our pricing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/pricing/E059.csv', 'data/pricing/9894.csv', 'data/pricing/9670.csv', 'data/pricing/9664.csv', 'data/pricing/8618.csv', 'data/pricing/9506.csv', 'data/pricing/9507.csv', 'data/pricing/8619.csv', 'data/pricing/9665.csv', 'data/pricing/9671.csv', 'data/pricing/9659.csv', 'data/pricing/9317.csv', 'data/pricing/9471.csv', 'data/pricing/9129.csv', 'data/pricing/9667.csv', 'data/pricing/9673.csv', 'data/pricing/9505.csv', 'data/pricing/9504.csv', 'data/pricing/9672.csv', 'data/pricing/9666.csv', 'data/pricing/9470.csv', 'data/pricing/9662.csv', 'data/pricing/9676.csv', 'data/pricing/9501.csv', 'data/pricing/9677.csv', 'data/pricing/9688.csv', 'data/pricing/9461.csv', 'data/pricing/9477.csv', 'data/pricing/E048.csv', 'data/pricing/9675.csv', 'data/pricing/9107.csv', 'data/pricing/9661.csv', 'data/pricing/9503.csv', 'data/pricing/8620.csv', 'data/pricing/9502.csv', 'data/pricing/9106.csv', 'data/pricing/9660.csv', 'data/pricing/9674.csv', 'data/pricing/9476.csv', 'data/pricing/E006.csv', 'data/pricing/9411.csv', 'data/pricing/9149.csv', 'data/pricing/9161.csv', 'data/pricing/9217.csv', 'data/pricing/9148.csv', 'data/pricing/9410.csv', 'data/pricing/E007.csv', 'data/pricing/9412.csv', 'data/pricing/E039.csv', 'data/pricing/9638.csv', 'data/pricing/9162.csv', 'data/pricing/9599.csv', 'data/pricing/9214.csv', 'data/pricing/9598.csv', 'data/pricing/9639.csv', 'data/pricing/E038.csv', 'data/pricing/9413.csv', 'data/pricing/E014.csv', 'data/pricing/9167.csv', 'data/pricing/9173.csv', 'data/pricing/9205.csv', 'data/pricing/9238.csv', 'data/pricing/9210.csv', 'data/pricing/9172.csv', 'data/pricing/9166.csv', 'data/pricing/E015.csv', 'data/pricing/9414.csv', 'data/pricing/9400.csv', 'data/pricing/E017.csv', 'data/pricing/9158.csv', 'data/pricing/9206.csv', 'data/pricing/9213.csv', 'data/pricing/9165.csv', 'data/pricing/E016.csv', 'data/pricing/9415.csv', 'data/pricing/9168.csv', 'data/pricing/9140.csv', 'data/pricing/9222.csv', 'data/pricing/9237.csv', 'data/pricing/9545.csv', 'data/pricing/9592.csv', 'data/pricing/9974.csv', 'data/pricing/9141.csv', 'data/pricing/E018.csv', 'data/pricing/9143.csv', 'data/pricing/9157.csv', 'data/pricing/9209.csv', 'data/pricing/9235.csv', 'data/pricing/9221.csv', 'data/pricing/9546.csv', 'data/pricing/9234.csv', 'data/pricing/9591.csv', 'data/pricing/9156.csv', 'data/pricing/9142.csv', 'data/pricing/9618.csv', 'data/pricing/E019.csv', 'data/pricing/9436.csv', 'data/pricing/E035.csv', 'data/pricing/9146.csv', 'data/pricing/9581.csv', 'data/pricing/9218.csv', 'data/pricing/9225.csv', 'data/pricing/9231.csv', 'data/pricing/9580.csv', 'data/pricing/9594.csv', 'data/pricing/9147.csv', 'data/pricing/E034.csv', 'data/pricing/E008.csv', 'data/pricing/E036.csv', 'data/pricing/9145.csv', 'data/pricing/9596.csv', 'data/pricing/9232.csv', 'data/pricing/9226.csv', 'data/pricing/9144.csv', 'data/pricing/E037.csv', 'data/pricing/9408.csv', 'data/pricing/9434.csv', 'data/pricing/E044.csv', 'data/pricing/9862.csv', 'data/pricing/9679.csv', 'data/pricing/9527.csv', 'data/pricing/9241.csv', 'data/pricing/9532.csv', 'data/pricing/9526.csv', 'data/pricing/9240.csv', 'data/pricing/9678.csv', 'data/pricing/9685.csv', 'data/pricing/9524.csv', 'data/pricing/9243.csv', 'data/pricing/9525.csv', 'data/pricing/9135.csv', 'data/pricing/E046.csv', 'data/pricing/E042.csv', 'data/pricing/9680.csv', 'data/pricing/9694.csv', 'data/pricing/9125.csv', 'data/pricing/9247.csv', 'data/pricing/8617.csv', 'data/pricing/9509.csv', 'data/pricing/9520.csv', 'data/pricing/9246.csv', 'data/pricing/9534.csv', 'data/pricing/9695.csv', 'data/pricing/9681.csv', 'data/pricing/E043.csv', 'data/pricing/9442.csv', 'data/pricing/E041.csv', 'data/pricing/9683.csv', 'data/pricing/9873.csv', 'data/pricing/9668.csv', 'data/pricing/9244.csv', 'data/pricing/9522.csv', 'data/pricing/9523.csv', 'data/pricing/9669.csv', 'data/pricing/9682.csv', 'data/pricing/E040.csv']\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    os.path.join(DATA_PATH, file)\n",
    "    for file in os.listdir(DATA_PATH)\n",
    "    if os.path.isfile(os.path.join(DATA_PATH, file)) and \".csv\" in file\n",
    "]\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Do the processing against all the files.\n",
    "for file in files:\n",
    "    # Make sure to load the data.\n",
    "    df = load_data(file)\n",
    "    if df is None:\n",
    "        continue\n",
    "\n",
    "    # Fill the gaps.\n",
    "    df = fill_gaps(df)\n",
    "\n",
    "    # Write it back.\n",
    "    df.to_csv(file, index_label=COLUMN_DATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
