{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "\n",
    "This notebook handles pre-processing all the data to make sure it is consistent and there are no gaps in it.\n",
    "\n",
    "Note: This notebook assumes that you have loaded data within the `data/portfolios.json` and `data/pricing` by running the `init.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lib imports.\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Typing.\n",
    "from typing import Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATA_PATH_IN = \"data/raw\"\n",
    "DATA_PATH_OUT = \"data/pricing\"\n",
    "FUNDS_PATH = \"data/portfolios.json\"\n",
    "\n",
    "# Columns.\n",
    "COLUMN_DATE = \"asOfDate\"\n",
    "COLUMN_PRICE = \"price\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition\n",
    "\n",
    "This section defines all the functions we need for later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Loads the data as per the specification of the pricing CSVs.\n",
    "\n",
    "    Args:\n",
    "        path (str): to the current file to load.\n",
    "\n",
    "    Returns:\n",
    "        Optional[pd.DataFrame]: with the pricing data sorted by date, ascending. None if there is no data.\n",
    "    \"\"\"\n",
    "    # Make sure it is a CSV and not something else.\n",
    "    if \".csv\" not in path:\n",
    "        return None\n",
    "\n",
    "    # Loads the data.\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        header=0,\n",
    "        index_col=COLUMN_DATE,\n",
    "        parse_dates=[COLUMN_DATE],\n",
    "        dtype={\n",
    "            \"price\": np.float64,\n",
    "            \"currencyCode\": np.string_,\n",
    "            \"__typename\": np.string_,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Sort by the index that we defined as date.\n",
    "    return df.sort_index(ascending=True, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_gaps(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Fills the gaps in the pricing data by backfilling from the previous existing dates.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): with potential gaps in the date index.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: with no gaps in the index.\n",
    "    \"\"\"\n",
    "    # Get all the possible dates.\n",
    "    date_min, date_max = (df.index.min(), df.index.max())\n",
    "\n",
    "    # We reindex using the min and max dates. This will propagate the values.\n",
    "    return df.reindex(pd.date_range(start=date_min, end=date_max), method=\"ffill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "This section tests the functions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_index_size(df: pd.DataFrame, verbose:bool = True) -> Tuple[int, int]:\n",
    "    # We can expect the number of rows to be less than a range of dates.\n",
    "    full_range_len = len(pd.date_range(start=df.index.min(), end=df.index.max()))\n",
    "    index_len = df.index.shape[0]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Full Size vs Index Size = {full_range_len} vs {index_len}\")\n",
    "    return full_range_len, index_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               price currencyCode __typename\n",
      "asOfDate                                    \n",
      "2016-11-08  100.0000          GBP  FundPrice\n",
      "2016-11-09   99.7742          GBP  FundPrice\n",
      "2016-11-10   99.7799          GBP  FundPrice\n",
      "2016-11-11   98.5293          GBP  FundPrice\n",
      "2016-11-14   99.3307          GBP  FundPrice\n",
      "...              ...          ...        ...\n",
      "2024-10-07  218.3068          GBP  FundPrice\n",
      "2024-10-08  218.1539          GBP  FundPrice\n",
      "2024-10-09  219.3834          GBP  FundPrice\n",
      "2024-10-10  219.6460          GBP  FundPrice\n",
      "2024-10-11  220.5142          GBP  FundPrice\n",
      "\n",
      "[2002 rows x 3 columns]\n",
      "Full Size vs Index Size = 2895 vs 2002\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_DATA = \"data/raw/8617.csv\"\n",
    "\n",
    "df = load_data(EXAMPLE_DATA)\n",
    "\n",
    "# We can verify that there a gap since the gaps occur in weekends where the market is closed.\n",
    "print(df)\n",
    "\n",
    "# Make sure we assert it.\n",
    "full_size, index_size = evaluate_index_size(df)\n",
    "assert full_size > index_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               price currencyCode __typename\n",
      "2016-11-08  100.0000          GBP  FundPrice\n",
      "2016-11-09   99.7742          GBP  FundPrice\n",
      "2016-11-10   99.7799          GBP  FundPrice\n",
      "2016-11-11   98.5293          GBP  FundPrice\n",
      "2016-11-12   98.5293          GBP  FundPrice\n",
      "...              ...          ...        ...\n",
      "2024-10-07  218.3068          GBP  FundPrice\n",
      "2024-10-08  218.1539          GBP  FundPrice\n",
      "2024-10-09  219.3834          GBP  FundPrice\n",
      "2024-10-10  219.6460          GBP  FundPrice\n",
      "2024-10-11  220.5142          GBP  FundPrice\n",
      "\n",
      "[2895 rows x 3 columns]\n",
      "Full Size vs Index Size = 2895 vs 2895\n"
     ]
    }
   ],
   "source": [
    "df = fill_gaps(df)\n",
    "\n",
    "# We can verify that now there shouldn't be any gaps.\n",
    "print(df)\n",
    "\n",
    "# Make sure we assert it.\n",
    "full_size, index_size = evaluate_index_size(df)\n",
    "assert full_size == index_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propagation\n",
    "\n",
    "Now we perform the propagation against ALL the data in our pricing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/raw/E059.csv', 'data/raw/9894.csv', 'data/raw/9670.csv', 'data/raw/9664.csv', 'data/raw/8618.csv', 'data/raw/9506.csv', 'data/raw/9507.csv', 'data/raw/8619.csv', 'data/raw/9665.csv', 'data/raw/9671.csv', 'data/raw/9659.csv', 'data/raw/9317.csv', 'data/raw/9471.csv', 'data/raw/9129.csv', 'data/raw/9667.csv', 'data/raw/9673.csv', 'data/raw/9505.csv', 'data/raw/9504.csv', 'data/raw/9672.csv', 'data/raw/9666.csv', 'data/raw/9470.csv', 'data/raw/9662.csv', 'data/raw/9676.csv', 'data/raw/9501.csv', 'data/raw/9677.csv', 'data/raw/9688.csv', 'data/raw/9461.csv', 'data/raw/9477.csv', 'data/raw/E048.csv', 'data/raw/9675.csv', 'data/raw/9107.csv', 'data/raw/9661.csv', 'data/raw/9503.csv', 'data/raw/8620.csv', 'data/raw/9502.csv', 'data/raw/9106.csv', 'data/raw/9660.csv', 'data/raw/9674.csv', 'data/raw/9476.csv', 'data/raw/E006.csv', 'data/raw/9411.csv', 'data/raw/9149.csv', 'data/raw/9161.csv', 'data/raw/9217.csv', 'data/raw/9148.csv', 'data/raw/9410.csv', 'data/raw/E007.csv', 'data/raw/9412.csv', 'data/raw/E039.csv', 'data/raw/9638.csv', 'data/raw/9162.csv', 'data/raw/9599.csv', 'data/raw/9214.csv', 'data/raw/9598.csv', 'data/raw/9639.csv', 'data/raw/E038.csv', 'data/raw/9413.csv', 'data/raw/E014.csv', 'data/raw/9167.csv', 'data/raw/9173.csv', 'data/raw/9205.csv', 'data/raw/9238.csv', 'data/raw/9210.csv', 'data/raw/9172.csv', 'data/raw/9166.csv', 'data/raw/E015.csv', 'data/raw/9414.csv', 'data/raw/9400.csv', 'data/raw/E017.csv', 'data/raw/9158.csv', 'data/raw/9206.csv', 'data/raw/9213.csv', 'data/raw/9165.csv', 'data/raw/E016.csv', 'data/raw/9415.csv', 'data/raw/9168.csv', 'data/raw/9140.csv', 'data/raw/9222.csv', 'data/raw/9237.csv', 'data/raw/9545.csv', 'data/raw/9592.csv', 'data/raw/9974.csv', 'data/raw/9141.csv', 'data/raw/E018.csv', 'data/raw/9143.csv', 'data/raw/9157.csv', 'data/raw/9209.csv', 'data/raw/9235.csv', 'data/raw/9221.csv', 'data/raw/9546.csv', 'data/raw/9234.csv', 'data/raw/9591.csv', 'data/raw/9156.csv', 'data/raw/9142.csv', 'data/raw/9618.csv', 'data/raw/E019.csv', 'data/raw/9436.csv', 'data/raw/E035.csv', 'data/raw/9146.csv', 'data/raw/9581.csv', 'data/raw/9218.csv', 'data/raw/9225.csv', 'data/raw/9231.csv', 'data/raw/9580.csv', 'data/raw/9594.csv', 'data/raw/9147.csv', 'data/raw/E034.csv', 'data/raw/E008.csv', 'data/raw/E036.csv', 'data/raw/9145.csv', 'data/raw/9596.csv', 'data/raw/9232.csv', 'data/raw/9226.csv', 'data/raw/9144.csv', 'data/raw/E037.csv', 'data/raw/9408.csv', 'data/raw/9434.csv', 'data/raw/E044.csv', 'data/raw/9862.csv', 'data/raw/9679.csv', 'data/raw/9527.csv', 'data/raw/9241.csv', 'data/raw/9532.csv', 'data/raw/9526.csv', 'data/raw/9240.csv', 'data/raw/9678.csv', 'data/raw/9685.csv', 'data/raw/9524.csv', 'data/raw/9243.csv', 'data/raw/9525.csv', 'data/raw/9135.csv', 'data/raw/E046.csv', 'data/raw/E042.csv', 'data/raw/9680.csv', 'data/raw/9694.csv', 'data/raw/9125.csv', 'data/raw/9247.csv', 'data/raw/8617.csv', 'data/raw/9509.csv', 'data/raw/9520.csv', 'data/raw/9246.csv', 'data/raw/9534.csv', 'data/raw/9695.csv', 'data/raw/9681.csv', 'data/raw/E043.csv', 'data/raw/9442.csv', 'data/raw/E041.csv', 'data/raw/9683.csv', 'data/raw/9873.csv', 'data/raw/9668.csv', 'data/raw/9244.csv', 'data/raw/9522.csv', 'data/raw/9523.csv', 'data/raw/9669.csv', 'data/raw/9682.csv', 'data/raw/E040.csv']\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    os.path.join(DATA_PATH_IN, file)\n",
    "    for file in os.listdir(DATA_PATH_IN)\n",
    "    if os.path.isfile(os.path.join(DATA_PATH_IN, file)) and \".csv\" in file\n",
    "]\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled 148195 rows across 156 porfolios!\n"
     ]
    }
   ],
   "source": [
    "total_filled = 0\n",
    "\n",
    "# Do the processing against all the files.\n",
    "for file in files:\n",
    "    # Make sure to load the data.\n",
    "    df = load_data(file)\n",
    "    if df is None:\n",
    "        continue\n",
    "\n",
    "    # Computes metrics.\n",
    "    total_len, index_len = evaluate_index_size(df, verbose=False)\n",
    "    total_filled += total_len - index_len\n",
    "\n",
    "    # Fill the gaps.\n",
    "    df = fill_gaps(df)\n",
    "\n",
    "    # Write it back.\n",
    "    df.to_csv(\n",
    "        os.path.join(DATA_PATH_OUT, os.path.split(file)[-1]), index_label=COLUMN_DATE\n",
    "    )\n",
    "\n",
    "print(f\"Filled {total_filled} rows across {len(files)} porfolios!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
